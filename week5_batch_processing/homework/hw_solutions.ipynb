{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 homework - Batch processing with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a local Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/23 19:43:42 WARN Utils: Your hostname, GRAD0365UBUNTU resolves to a loopback address: 127.0.1.1; using 192.168.1.151 instead (on interface wlp0s20f3)\n",
      "23/02/23 19:43:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/23 19:43:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"dtc_hw\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "**Check Spark version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data and save it to Parquet\n",
    "\n",
    "For this homework we will be using the FHVHV 2021-06 data found here: [FHVHV Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz).\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons.</br> \n",
    "Repartition it to 12 partitions and save it to parquet.</br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-23 19:43:45--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz\n",
      "Resolviendo github.com (github.com)... 140.82.121.3\n",
      "Conectando con github.com (github.com)[140.82.121.3]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Ubicación: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230223T184345Z&X-Amz-Expires=300&X-Amz-Signature=9c7f04268141e4157cdc95f7da763c8695e33ab0abf570f98a9793ae22c2fe65&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream [siguiente]\n",
      "--2023-02-23 19:43:45--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230223T184345Z&X-Amz-Expires=300&X-Amz-Signature=9c7f04268141e4157cdc95f7da763c8695e33ab0abf570f98a9793ae22c2fe65&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolviendo objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Conectando con objects.githubusercontent.com (objects.githubusercontent.com)[185.199.109.133]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 175799316 (168M) [application/octet-stream]\n",
      "Guardando como: “../data/fhvhv_tripdata_2021-06.csv.gz”\n",
      "\n",
      "../data/fhvhv_tripd 100%[===================>] 167,66M  18,5MB/s    en 9,3s    \n",
      "\n",
      "2023-02-23 19:43:55 (18,0 MB/s) - “../data/fhvhv_tripdata_2021-06.csv.gz” guardado [175799316/175799316]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download file\n",
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz -O ../data/fhvhv_tripdata_2021-06.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the data and check schema\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"../data/fhvhv_tripdata_2021-06.csv.gz\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B02764', pickup_datetime='2021-06-01 00:02:41', dropoff_datetime='2021-06-01 00:07:46', PULocationID='174', DOLocationID='18', SR_Flag='N', Affiliated_base_number='B02764'),\n",
       " Row(dispatching_base_num='B02764', pickup_datetime='2021-06-01 00:16:16', dropoff_datetime='2021-06-01 00:21:14', PULocationID='32', DOLocationID='254', SR_Flag='N', Affiliated_base_number='B02764'),\n",
       " Row(dispatching_base_num='B02764', pickup_datetime='2021-06-01 00:27:01', dropoff_datetime='2021-06-01 00:42:11', PULocationID='240', DOLocationID='127', SR_Flag='N', Affiliated_base_number='B02764'),\n",
       " Row(dispatching_base_num='B02764', pickup_datetime='2021-06-01 00:46:08', dropoff_datetime='2021-06-01 00:53:45', PULocationID='127', DOLocationID='235', SR_Flag='N', Affiliated_base_number='B02764'),\n",
       " Row(dispatching_base_num='B02510', pickup_datetime='2021-06-01 00:45:42', dropoff_datetime='2021-06-01 01:03:33', PULocationID='144', DOLocationID='146', SR_Flag='N', Affiliated_base_number=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a schema for the dataframe\n",
    "schema = types.StructType([\n",
    "        types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "        types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "        types.StructField('dropoff_datetime', types.TimestampType(), True), \n",
    "        types.StructField('PULocationID', types.IntegerType(), True), \n",
    "        types.StructField('DOLocationID', types.IntegerType(), True), \n",
    "        types.StructField('SR_Flag', types.StringType(), True),\n",
    "        types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/23 19:44:37 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# re-read the data using the schema we want\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"../data/fhvhv_tripdata_2021-06.csv.gz\")\n",
    "\n",
    "# repartition\n",
    "df = df.repartition(12)\n",
    "\n",
    "# save to parquet\n",
    "df.write.parquet(\"../data/fhvhv/2021/06\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "**What is the average size of the Parquet (ending with .parquet extension) files that were created (in MB)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00000-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00001-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00002-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00003-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00004-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00005-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00006-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00007-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00008-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00009-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00010-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 sgrodriguez usuarios del dominio 24M feb 23 19:44 ../data/fhvhv/2021/06/part-00011-8040fd6d-ba69-4dd1-9eb9-388e3477b1f0-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../data/fhvhv/2021/06/*.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the previous command, all the Parquet files have a size of **24MB**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "**How many taxi trips were there on June 15? Consider only trips that started on June 15.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn(\"pickup_date\", F.to_date(df.pickup_datetime)) \\\n",
    "    .filter(\"pickup_date == '2021-06-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's solve it also via Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the dataframe as a table\n",
    "df.createOrReplaceTempView(\"fhvhv_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|trips_count|\n",
      "+-----------+\n",
      "|     452470|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(1) AS trips_count\n",
    "FROM fhvhv_table\n",
    "WHERE TO_DATE(pickup_datetime) = '2021-06-15';\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "**Longest trip for each day.**  \n",
    "**Calculate the duration for each trip. How long was the longest trip in Hours?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:==========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+\n",
      "|pickup_date|longest_trip_duration|\n",
      "+-----------+---------------------+\n",
      "| 2021-06-25|     66.8788888888889|\n",
      "| 2021-06-22|   25.549722222222222|\n",
      "| 2021-06-27|   19.980833333333333|\n",
      "| 2021-06-26|   18.197222222222223|\n",
      "| 2021-06-23|   16.466944444444444|\n",
      "+-----------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn(\"trip_duration\", (df.dropoff_datetime.cast(\"long\") - df.pickup_datetime.cast(\"long\")) / 3600) \\\n",
    "    .withColumn(\"pickup_date\", F.to_date(df.pickup_datetime)) \\\n",
    "    .select(\"pickup_date\", \"trip_duration\") \\\n",
    "    .groupBy(\"pickup_date\") \\\n",
    "    .agg(F.max(\"trip_duration\").alias(\"longest_trip_duration\")) \\\n",
    "    .orderBy(\"longest_trip_duration\", ascending=False) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+\n",
      "|pickup_date|longest_trip_duration|\n",
      "+-----------+---------------------+\n",
      "| 2021-06-25|     66.8788888888889|\n",
      "| 2021-06-22|   25.549722222222222|\n",
      "| 2021-06-27|   19.980833333333333|\n",
      "| 2021-06-26|   18.197222222222223|\n",
      "| 2021-06-23|   16.466944444444444|\n",
      "+-----------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 25:===================================================>    (11 + 1) / 12]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    TO_DATE(pickup_datetime) AS pickup_date,\n",
    "    MAX((CAST(dropoff_datetime AS LONG) - CAST(pickup_datetime AS LONG)) / 3600) AS longest_trip_duration\n",
    "FROM fhvhv_table\n",
    "GROUP BY pickup_date\n",
    "ORDER BY longest_trip_duration DESC\n",
    "LIMIT 5;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the longest trip lasted **66.88 hours**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "**User interface.**  \n",
    "**Spark’s User Interface which shows application's dashboard runs on which local port?**  \n",
    "\n",
    "Spark's UI runs at **`localhost:4040`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "**Most frequent pickup location zone**  \n",
    "\n",
    "Load the zone lookup data into a temp view in Spark: [Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)  \n",
    "\n",
    "**What is the name of the most frequent pickup location zone?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-23 19:46:23--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolviendo github.com (github.com)... 140.82.121.4\n",
      "Conectando con github.com (github.com)[140.82.121.4]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Ubicación: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230223T184624Z&X-Amz-Expires=300&X-Amz-Signature=a1436d73d78f2f84c000780d65f835bf5b8470d48ac2294e49e4ff7beeda6737&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [siguiente]\n",
      "--2023-02-23 19:46:24--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230223T184624Z&X-Amz-Expires=300&X-Amz-Signature=a1436d73d78f2f84c000780d65f835bf5b8470d48ac2294e49e4ff7beeda6737&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolviendo objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Conectando con objects.githubusercontent.com (objects.githubusercontent.com)[185.199.111.133]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 12322 (12K) [application/octet-stream]\n",
      "Guardando como: “../data/taxi_zone_lookup.csv”\n",
      "\n",
      "../data/taxi_zone_l 100%[===================>]  12,03K  --.-KB/s    en 0s      \n",
      "\n",
      "2023-02-23 19:46:24 (41,4 MB/s) - “../data/taxi_zone_lookup.csv” guardado [12322/12322]\n",
      "\n",
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download zone lookup data\n",
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv -O ../data/taxi_zone_lookup.csv\n",
    "\n",
    "# read data into a dataframe\n",
    "df_zones = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(\"../data/taxi_zone_lookup.csv\")\n",
    "df_zones.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                Zone| count|\n",
      "+--------------------+------+\n",
      "| Crown Heights North|231279|\n",
      "|        East Village|221244|\n",
      "|         JFK Airport|188867|\n",
      "|      Bushwick South|187929|\n",
      "|       East New York|186780|\n",
      "|TriBeCa/Civic Center|164344|\n",
      "|   LaGuardia Airport|161596|\n",
      "|            Union Sq|158937|\n",
      "|        West Village|154698|\n",
      "|             Astoria|152493|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 34:===================================================>    (11 + 1) / 12]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .join(df_zones, on=df.PULocationID == df_zones.LocationID, how=\"left\") \\\n",
    "    .groupBy(\"Zone\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False) \\\n",
    "    .limit(10) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.createOrReplaceTempView(\"zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|                zone|number_trips|\n",
      "+--------------------+------------+\n",
      "| Crown Heights North|      231279|\n",
      "|        East Village|      221244|\n",
      "|         JFK Airport|      188867|\n",
      "|      Bushwick South|      187929|\n",
      "|       East New York|      186780|\n",
      "|TriBeCa/Civic Center|      164344|\n",
      "|   LaGuardia Airport|      161596|\n",
      "|            Union Sq|      158937|\n",
      "|        West Village|      154698|\n",
      "|             Astoria|      152493|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    zones.Zone AS zone,\n",
    "    COUNT(trips.PULocationID) AS number_trips\n",
    "FROM fhvhv_table AS trips\n",
    "LEFT JOIN zones\n",
    "ON trips.PULocationID = zones.LocationID\n",
    "GROUP BY zone\n",
    "ORDER BY number_trips DESC\n",
    "LIMIT 10;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the most frequent pickup location zone is **Crown Heights North**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
