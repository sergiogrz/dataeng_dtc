{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57672d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971b1728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 14:45:16 WARN Utils: Your hostname, GRAD0365UBUNTU resolves to a loopback address: 127.0.1.1; using 192.168.1.151 instead (on interface wlp0s20f3)\n",
      "23/02/15 14:45:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 14:45:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"test\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c149ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read.parquet(\"../data/pq/green/*/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69045b",
   "metadata": {},
   "source": [
    "## Reproduce query with RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe6033c",
   "metadata": {},
   "source": [
    "We want to implement with RDDs the following query from `03_groupby_join.ipynb` notebook.\n",
    "\n",
    "```\n",
    "SELECT \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour,\n",
    "    PULocationID AS revenue_zone,\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    green_data\n",
    "WHERE lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512451f",
   "metadata": {},
   "source": [
    "### From dataframe to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a378200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[7] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb041e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 12, 18, 15, 4), lpep_dropoff_datetime=datetime.datetime(2020, 1, 12, 18, 19, 52), store_and_fwd_flag='N', RatecodeID=1, PULocationID=41, DOLocationID=41, passenger_count=1, trip_distance=0.78, fare_amount=5.5, extra=0.0, mta_tax=0.5, tip_amount=1.58, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=7.88, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 31, 20, 24, 10), lpep_dropoff_datetime=datetime.datetime(2020, 1, 31, 20, 31, 51), store_and_fwd_flag='N', RatecodeID=1, PULocationID=173, DOLocationID=70, passenger_count=1, trip_distance=0.98, fare_amount=7.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 7, 8, 16, 53), lpep_dropoff_datetime=datetime.datetime(2020, 1, 7, 8, 41, 39), store_and_fwd_flag='N', RatecodeID=1, PULocationID=74, DOLocationID=236, passenger_count=1, trip_distance=2.7, fare_amount=16.0, extra=0.0, mta_tax=0.5, tip_amount=3.91, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=23.46, payment_type=1, trip_type=1, congestion_surcharge=2.75)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29aee5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 12, 18, 15, 4), lpep_dropoff_datetime=datetime.datetime(2020, 1, 12, 18, 19, 52), store_and_fwd_flag='N', RatecodeID=1, PULocationID=41, DOLocationID=41, passenger_count=1, trip_distance=0.78, fare_amount=5.5, extra=0.0, mta_tax=0.5, tip_amount=1.58, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=7.88, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 31, 20, 24, 10), lpep_dropoff_datetime=datetime.datetime(2020, 1, 31, 20, 31, 51), store_and_fwd_flag='N', RatecodeID=1, PULocationID=173, DOLocationID=70, passenger_count=1, trip_distance=0.98, fare_amount=7.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 7, 8, 16, 53), lpep_dropoff_datetime=datetime.datetime(2020, 1, 7, 8, 41, 39), store_and_fwd_flag='N', RatecodeID=1, PULocationID=74, DOLocationID=236, passenger_count=1, trip_distance=2.7, fare_amount=16.0, extra=0.0, mta_tax=0.5, tip_amount=3.91, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=23.46, payment_type=1, trip_type=1, congestion_surcharge=2.75)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4a6bb",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ee738c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 12, 18, 15, 4), PULocationID=41, total_amount=7.88),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 31, 20, 24, 10), PULocationID=173, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 7, 8, 16, 53), PULocationID=74, total_amount=23.46)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select only the columns we need for our query\n",
    "rdd = df_green \\\n",
    "    .select(\"lpep_pickup_datetime\", \"PULocationID\", \"total_amount\") \\\n",
    "    .rdd\n",
    "\n",
    "rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f9b158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 12, 18, 15, 4), PULocationID=41, total_amount=7.88),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 31, 20, 24, 10), PULocationID=173, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 7, 8, 16, 53), PULocationID=74, total_amount=23.46)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter based on the WHERE clause of the query\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime(year=2020, month=1, day=1)\n",
    "\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start\n",
    "\n",
    "rdd.filter(filter_outliers).take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd797dfb",
   "metadata": {},
   "source": [
    "### Map\n",
    "\n",
    "We need to generate intermediate results in a very similar way to the original SQL query, so we will need to create the composite key `(hour, revenue_zone)` and a composite value `(amount, count)`, which are the 2 halves of each record that the executors will generate. Once we have a function that generates the record, we will use the `map()` method, which takes an RDD, transforms it with a function (our key-value function) and returns a new RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ecffd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 12, 18, 15, 4), PULocationID=41, total_amount=7.88)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = rdd.take(1)[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79afcbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 1, 12, 18, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.lpep_pickup_datetime.replace(minute=0, second=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "630dcb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_grouping(row):\n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0)\n",
    "    revenue_zone = row.PULocationID\n",
    "    key = (hour, revenue_zone)\n",
    "    \n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    value = (amount, count)\n",
    "    \n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "714cad0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 12, 18, 0), 41), (7.88, 1)),\n",
       " ((datetime.datetime(2020, 1, 31, 20, 0), 173), (8.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 7, 8, 0), 74), (23.46, 1)),\n",
       " ((datetime.datetime(2020, 1, 15, 14, 0), 25), (7.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 31, 10, 0), 259), (25.54, 1))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f7171",
   "metadata": {},
   "source": [
    "### ReduceByKey\n",
    "\n",
    "We now need to use the `reduceByKey()` method, which will reduce all the records with the same key to a single record. Since we want to count the total amount and the total number of records, we just need to add the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d76228a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_revenue(left_value, right_value):\n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "    \n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "    \n",
    "    return (output_amount, output_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2206d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 13, 10, 0), 165), (55.43000000000001, 3)),\n",
       " ((datetime.datetime(2020, 1, 23, 10, 0), 43), (315.40000000000003, 19)),\n",
       " ((datetime.datetime(2020, 1, 2, 9, 0), 116), (296.54, 17)),\n",
       " ((datetime.datetime(2020, 1, 31, 21, 0), 41), (588.1599999999999, 40)),\n",
       " ((datetime.datetime(2020, 1, 26, 0, 0), 258), (56.92, 1))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31791d4e",
   "metadata": {},
   "source": [
    "### From RDD to dataframe\n",
    "\n",
    "The nested structure above is not very useful to work with, so we are going to unnested it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eefeae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(row):\n",
    "    return (row[0][0], row[0][1], row[1][0], row[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67a08e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2020, 1, 13, 10, 0), 165, 55.43000000000001, 3),\n",
       " (datetime.datetime(2020, 1, 23, 10, 0), 43, 315.40000000000003, 19),\n",
       " (datetime.datetime(2020, 1, 2, 9, 0), 116, 296.54, 17),\n",
       " (datetime.datetime(2020, 1, 31, 21, 0), 41, 588.1599999999999, 40),\n",
       " (datetime.datetime(2020, 1, 26, 0, 0), 258, 56.92, 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187a510",
   "metadata": {},
   "source": [
    "Finally, we turn the structure back to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbc69e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------------------+---+\n",
      "|                 _1| _2|                _3| _4|\n",
      "+-------------------+---+------------------+---+\n",
      "|2020-01-13 10:00:00|165| 55.43000000000001|  3|\n",
      "|2020-01-23 10:00:00| 43|315.40000000000003| 19|\n",
      "|2020-01-02 09:00:00|116|            296.54| 17|\n",
      "|2020-01-31 21:00:00| 41| 588.1599999999999| 40|\n",
      "|2020-01-26 00:00:00|258|             56.92|  1|\n",
      "+-------------------+---+------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF() \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465aa15f",
   "metadata": {},
   "source": [
    "The column names have been lost in the first `map()` operation, so we can do it a bit differently to keep the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c69f09ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "RevenueRow = namedtuple(\"RevenueRow\", [\"hour\", \"revenue_zone\", \"revenue\", \"count\"])\n",
    "\n",
    "def unwrap(row):\n",
    "    return RevenueRow(\n",
    "        hour=row[0][0],\n",
    "        revenue_zone=row[0][1],\n",
    "        revenue=row[1][0], \n",
    "        count=row[1][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e85cf4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e5df587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+------------------+-----+\n",
      "|               hour|revenue_zone|           revenue|count|\n",
      "+-------------------+------------+------------------+-----+\n",
      "|2020-01-13 10:00:00|         165| 55.43000000000001|    3|\n",
      "|2020-01-23 10:00:00|          43|315.40000000000003|   19|\n",
      "|2020-01-02 09:00:00|         116|            296.54|   17|\n",
      "|2020-01-31 21:00:00|          41| 588.1599999999999|   40|\n",
      "|2020-01-26 00:00:00|         258|             56.92|    1|\n",
      "+-------------------+------------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e1e2fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hour', TimestampType(), True), StructField('revenue_zone', LongType(), True), StructField('revenue', DoubleType(), True), StructField('count', LongType(), True)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efc7f5",
   "metadata": {},
   "source": [
    "We want to change the schema to the one below:\n",
    "\n",
    "```\n",
    "types.StructType([\n",
    "    types.StructField('hour', types.TimestampType(), True),\n",
    "    types.StructField('revenue_zone', types.IntegerType(), True),\n",
    "    types.StructField('revenue', types.DoubleType(), True),\n",
    "    types.StructField('count', types.IntegerType(), True)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86f04124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20050e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_schema = types.StructType([\n",
    "    types.StructField('hour', types.TimestampType(), True),\n",
    "    types.StructField('revenue_zone', types.IntegerType(), True),\n",
    "    types.StructField('revenue', types.DoubleType(), True),\n",
    "    types.StructField('count', types.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff43f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF(result_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cab7c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+------------------+-----+\n",
      "|               hour|revenue_zone|           revenue|count|\n",
      "+-------------------+------------+------------------+-----+\n",
      "|2020-01-13 10:00:00|         165| 55.43000000000001|    3|\n",
      "|2020-01-23 10:00:00|          43|315.40000000000003|   19|\n",
      "|2020-01-02 09:00:00|         116|            296.54|   17|\n",
      "|2020-01-31 21:00:00|          41| 588.1599999999999|   40|\n",
      "|2020-01-26 00:00:00|         258|             56.92|    1|\n",
      "+-------------------+------------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e315ca3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hour: timestamp (nullable = true)\n",
      " |-- revenue_zone: integer (nullable = true)\n",
      " |-- revenue: double (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d714fe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 14:46:08 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.write.parquet(\"../data/tmp/green-revenue\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eeac9a",
   "metadata": {},
   "source": [
    "### mapPartitions\n",
    "\n",
    "Similar to **map()** function, **mapPartitions()** gets in a partition and outputs another partition. \n",
    "\n",
    "Let's imagine we want to create an application or a service that predicts the duration of a trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "056240c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec135ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------+------------+-------------+\n",
      "|VendorID|lpep_pickup_datetime|PULocationID|DOLocationID|trip_distance|\n",
      "+--------+--------------------+------------+------------+-------------+\n",
      "|       2| 2020-01-12 18:15:04|          41|          41|         0.78|\n",
      "|       2| 2020-01-31 20:24:10|         173|          70|         0.98|\n",
      "|       2| 2020-01-07 08:16:53|          74|         236|          2.7|\n",
      "|       1| 2020-01-15 14:47:15|          25|          66|          0.8|\n",
      "|    null| 2020-01-31 10:08:00|         259|          51|         2.33|\n",
      "+--------+--------------------+------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"VendorID\", \"lpep_pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"trip_distance\"]\n",
    "\n",
    "df_green \\\n",
    "    .select(columns) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb935a20",
   "metadata": {},
   "source": [
    "To apply a ML model, we convert the dataframe to an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1cce76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 12, 18, 15, 4), PULocationID=41, DOLocationID=41, trip_distance=0.78),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 31, 20, 24, 10), PULocationID=173, DOLocationID=70, trip_distance=0.98),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 7, 8, 16, 53), PULocationID=74, DOLocationID=236, trip_distance=2.7),\n",
       " Row(VendorID=1, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 14, 47, 15), PULocationID=25, DOLocationID=66, trip_distance=0.8),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 31, 10, 8), PULocationID=259, DOLocationID=51, trip_distance=2.33)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_rdd = df_green \\\n",
    "    .select(columns) \\\n",
    "    .rdd\n",
    "duration_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f10a624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[746744, 418184, 219219, 215720, 212420, 199320, 183795, 109115]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of how mapPartitions works\n",
    "# count the lines in each partition\n",
    "def apply_model_in_batch(partition):\n",
    "    cnt = 0\n",
    "    for row in partition:\n",
    "        cnt += 1\n",
    "    \n",
    "    return [cnt]\n",
    "\n",
    "duration_rdd.mapPartitions(apply_model_in_batch).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ef6424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[746744, 418184, 219219, 215720, 212420, 199320, 183795, 109115]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def apply_model_in_batch(rows):\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    cnt = len(df)\n",
    "\n",
    "    return [cnt]\n",
    "\n",
    "duration_rdd.mapPartitions(apply_model_in_batch).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b06bb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ...\n",
    "\n",
    "\n",
    "def model_predict(df):\n",
    "    # y_pred = model.predict(df)\n",
    "    y_pred = df.trip_distance * 5\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a08be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model_in_batch(rows):\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    predictions = model_predict(df)\n",
    "    df[\"predicted_duration\"] = predictions\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        yield row\n",
    "\n",
    "    return [cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72ceaef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Pandas(Index=0, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-12 18:15:04'), PULocationID=41, DOLocationID=41, trip_distance=0.78, predicted_duration=3.9000000000000004),\n",
       " Pandas(Index=1, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-31 20:24:10'), PULocationID=173, DOLocationID=70, trip_distance=0.98, predicted_duration=4.9),\n",
       " Pandas(Index=2, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-07 08:16:53'), PULocationID=74, DOLocationID=236, trip_distance=2.7, predicted_duration=13.5),\n",
       " Pandas(Index=3, VendorID=1.0, lpep_pickup_datetime=Timestamp('2020-01-15 14:47:15'), PULocationID=25, DOLocationID=66, trip_distance=0.8, predicted_duration=4.0),\n",
       " Pandas(Index=4, VendorID=nan, lpep_pickup_datetime=Timestamp('2020-01-31 10:08:00'), PULocationID=259, DOLocationID=51, trip_distance=2.33, predicted_duration=11.65),\n",
       " Pandas(Index=5, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-18 17:46:45'), PULocationID=177, DOLocationID=188, trip_distance=2.62, predicted_duration=13.100000000000001),\n",
       " Pandas(Index=6, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-17 20:08:44'), PULocationID=65, DOLocationID=97, trip_distance=1.13, predicted_duration=5.6499999999999995),\n",
       " Pandas(Index=7, VendorID=nan, lpep_pickup_datetime=Timestamp('2020-01-13 10:47:00'), PULocationID=165, DOLocationID=123, trip_distance=1.36, predicted_duration=6.800000000000001),\n",
       " Pandas(Index=8, VendorID=nan, lpep_pickup_datetime=Timestamp('2020-01-07 15:36:00'), PULocationID=170, DOLocationID=220, trip_distance=11.15, predicted_duration=55.75),\n",
       " Pandas(Index=9, VendorID=nan, lpep_pickup_datetime=Timestamp('2020-01-10 11:47:00'), PULocationID=74, DOLocationID=41, trip_distance=1.78, predicted_duration=8.9)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_rdd.mapPartitions(apply_model_in_batch).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c89f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_predicts = duration_rdd \\\n",
    "    .mapPartitions(apply_model_in_batch) \\\n",
    "    .toDF() \\\n",
    "    .drop(\"Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccb93bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------+------------+-------------+------------------+\n",
      "|VendorID|lpep_pickup_datetime|PULocationID|DOLocationID|trip_distance|predicted_duration|\n",
      "+--------+--------------------+------------+------------+-------------+------------------+\n",
      "|     2.0|                  {}|          41|          41|         0.78|3.9000000000000004|\n",
      "|     2.0|                  {}|         173|          70|         0.98|               4.9|\n",
      "|     2.0|                  {}|          74|         236|          2.7|              13.5|\n",
      "|     1.0|                  {}|          25|          66|          0.8|               4.0|\n",
      "|     NaN|                  {}|         259|          51|         2.33|             11.65|\n",
      "|     2.0|                  {}|         177|         188|         2.62|13.100000000000001|\n",
      "|     2.0|                  {}|          65|          97|         1.13|5.6499999999999995|\n",
      "|     NaN|                  {}|         165|         123|         1.36| 6.800000000000001|\n",
      "|     NaN|                  {}|         170|         220|        11.15|             55.75|\n",
      "|     NaN|                  {}|          74|          41|         1.78|               8.9|\n",
      "|     1.0|                  {}|          75|          41|          1.0|               5.0|\n",
      "|     2.0|                  {}|          74|         151|         2.75|             13.75|\n",
      "|     1.0|                  {}|          41|          74|          1.1|               5.5|\n",
      "|     2.0|                  {}|         116|          74|         3.81|             19.05|\n",
      "|     2.0|                  {}|         152|         244|         1.85|              9.25|\n",
      "|     NaN|                  {}|          71|          88|         9.14|              45.7|\n",
      "|     2.0|                  {}|          43|         236|         1.04|               5.2|\n",
      "|     2.0|                  {}|          65|          49|         1.14| 5.699999999999999|\n",
      "|     NaN|                  {}|         254|         254|         1.15|              5.75|\n",
      "|     2.0|                  {}|         116|         244|         0.92|4.6000000000000005|\n",
      "+--------+--------------------+------------+------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_predicts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f18c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
