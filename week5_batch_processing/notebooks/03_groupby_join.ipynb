{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa01f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab95d319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 09:16:14 WARN Utils: Your hostname, GRAD0365UBUNTU resolves to a loopback address: 127.0.1.1; using 192.168.1.151 instead (on interface wlp0s20f3)\n",
      "23/02/15 09:16:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 09:16:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"test\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc371a",
   "metadata": {},
   "source": [
    "## GroupBy\n",
    "### Green taxi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2347fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet(\"../data/pq/green/*/*\")\n",
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede83711",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green.createOrReplaceTempView(\"green_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41085ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour,\n",
    "    PULocationID AS revenue_zone,\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    green_data\n",
    "WHERE lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024d047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+-----------------+--------------+\n",
      "|               hour|revenue_zone|           amount|number_records|\n",
      "+-------------------+------------+-----------------+--------------+\n",
      "|2020-01-24 09:00:00|          81|            59.49|             2|\n",
      "|2020-01-04 21:00:00|          25|           513.83|            32|\n",
      "|2020-01-10 19:00:00|          66|545.6800000000001|            27|\n",
      "|2020-01-30 07:00:00|          75|556.6600000000001|            40|\n",
      "|2020-01-18 01:00:00|         260|           144.56|            12|\n",
      "+-------------------+------------+-----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b0e645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 09:16:22 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "23/02/15 09:16:22 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:=======================>                                  (8 + 8) / 20]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet(\"../data/report/revenue/green\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5fd83",
   "metadata": {},
   "source": [
    "### Yellow taxi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf08e0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow = spark.read.parquet(\"../data/pq/yellow/*/*\")\n",
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa2a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow.createOrReplaceTempView(\"yellow_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360afe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', tpep_pickup_datetime) AS hour,\n",
    "    PULocationID AS revenue_zone,\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    yellow_data\n",
    "WHERE tpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e692f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 09:16:28 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "23/02/15 09:16:28 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet(\"../data/report/revenue/yellow\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4560ea6",
   "metadata": {},
   "source": [
    "## Joins\n",
    "\n",
    "### Joining two large tables\n",
    "\n",
    "We now want to join the two tables we've just created by hour and by zone. The result will be a table with 6 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "329867aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed(\"amount\", \"green_amount\") \\\n",
    "    .withColumnRenamed(\"number_records\", \"green_number_records\")\n",
    "\n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed(\"amount\", \"yellow_amount\") \\\n",
    "    .withColumnRenamed(\"number_records\", \"yellow_number_records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e1ebce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on=[\"hour\", \"revenue_zone\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "524c8ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hour: timestamp, revenue_zone: int, green_amount: double, green_number_records: bigint, yellow_amount: double, yellow_number_records: bigint]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016e31df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+------------------+--------------------+------------------+---------------------+\n",
      "|               hour|revenue_zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|\n",
      "+-------------------+------------+------------------+--------------------+------------------+---------------------+\n",
      "|2020-01-01 00:00:00|          22|              15.8|                   1|              null|                 null|\n",
      "|2020-01-01 00:00:00|          25|             531.0|                  26|            324.35|                   16|\n",
      "|2020-01-01 00:00:00|          55|129.29000000000002|                   4|              null|                 null|\n",
      "|2020-01-01 00:00:00|          56|             99.69|                   3|              18.1|                    2|\n",
      "|2020-01-01 00:00:00|          60|            160.04|                   6|57.620000000000005|                    2|\n",
      "+-------------------+------------+------------------+--------------------+------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0618ebba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:==========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 09:16:38 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.write.parquet(\"../data/report/revenue/total\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5a84ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+------------------+--------------------+------------------+---------------------+\n",
      "|               hour|revenue_zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|\n",
      "+-------------------+------------+------------------+--------------------+------------------+---------------------+\n",
      "|2020-01-01 00:00:00|          17|            195.03|                   9|220.20999999999998|                    8|\n",
      "|2020-01-01 00:00:00|          18|               7.8|                   1|               5.8|                    1|\n",
      "|2020-01-01 00:00:00|          24|              87.6|                   3|            754.95|                   45|\n",
      "|2020-01-01 00:00:00|          32| 68.94999999999999|                   2|              18.0|                    1|\n",
      "|2020-01-01 00:00:00|          49|266.76000000000005|                  14|            185.65|                   10|\n",
      "+-------------------+------------+------------------+--------------------+------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.read.parquet(\"../data/report/revenue/total\")\n",
    "df_join.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a54a24",
   "metadata": {},
   "source": [
    "### Joining a large and a small table\n",
    "\n",
    "We are going to use the `zones` lookup table to identify the `revenue_zone` from `df_join` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb8b298a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-15 09:16:39--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolviendo github.com (github.com)... 140.82.121.4\n",
      "Conectando con github.com (github.com)[140.82.121.4]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Ubicación: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230215%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230215T081639Z&X-Amz-Expires=300&X-Amz-Signature=74348becc5239208e3ec3acb898a69f0e0b1fd9a9a989f702be0cce93b59dfc3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [siguiente]\n",
      "--2023-02-15 09:16:39--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230215%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230215T081639Z&X-Amz-Expires=300&X-Amz-Signature=74348becc5239208e3ec3acb898a69f0e0b1fd9a9a989f702be0cce93b59dfc3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolviendo objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Conectando con objects.githubusercontent.com (objects.githubusercontent.com)[185.199.111.133]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 12322 (12K) [application/octet-stream]\n",
      "Guardando como: “../data/taxi_zone_lookup.csv”\n",
      "\n",
      "../data/taxi_zone_l 100%[===================>]  12,03K  --.-KB/s    en 0,02s   \n",
      "\n",
      "2023-02-15 09:16:40 (523 KB/s) - “../data/taxi_zone_lookup.csv” guardado [12322/12322]\n",
      "\n",
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv -O \"../data/taxi_zone_lookup.csv\"\n",
    "\n",
    "df_zones = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(\"../data/taxi_zone_lookup.csv\")\n",
    "df_zones.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecf66be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+------------------+--------------------+------------------+---------------------+---------+--------------------+------------+\n",
      "|               hour|revenue_zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|  Borough|                Zone|service_zone|\n",
      "+-------------------+------------+------------------+--------------------+------------------+---------------------+---------+--------------------+------------+\n",
      "|2020-01-01 00:00:00|          17|            195.03|                   9|220.20999999999998|                    8| Brooklyn|             Bedford|   Boro Zone|\n",
      "|2020-01-01 00:00:00|          18|               7.8|                   1|               5.8|                    1|    Bronx|        Bedford Park|   Boro Zone|\n",
      "|2020-01-01 00:00:00|          24|              87.6|                   3|            754.95|                   45|Manhattan|        Bloomingdale| Yellow Zone|\n",
      "|2020-01-01 00:00:00|          32| 68.94999999999999|                   2|              18.0|                    1|    Bronx|           Bronxdale|   Boro Zone|\n",
      "|2020-01-01 00:00:00|          49|266.76000000000005|                  14|            185.65|                   10| Brooklyn|        Clinton Hill|   Boro Zone|\n",
      "|2020-01-01 00:00:00|          89|              11.3|                   1|             48.16|                    2| Brooklyn|Flatbush/Ditmas Park|   Boro Zone|\n",
      "|2020-01-01 00:00:00|          93|              null|                null|210.27999999999997|                    3|   Queens|Flushing Meadows-...|   Boro Zone|\n",
      "|2020-01-01 00:00:00|         108|              null|                null|              18.8|                    1| Brooklyn|           Gravesend|   Boro Zone|\n",
      "|2020-01-01 00:00:00|         146| 99.36999999999999|                   6|110.74000000000001|                    7|   Queens|Long Island City/...|   Boro Zone|\n",
      "|2020-01-01 00:00:00|         168| 82.00999999999999|                   5|              20.1|                    2|    Bronx|Mott Haven/Port M...|   Boro Zone|\n",
      "+-------------------+------------+------------------+--------------------+------------------+---------------------+---------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = df_join.join(df_zones, on=df_join.revenue_zone == df_zones.LocationID)\n",
    "\n",
    "df_result.drop(\"LocationID\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83894d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 09:17:20 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.drop(\"LocationID\").write.parquet(\"../data/tmp/revenue-zones\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fb21691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hour: timestamp, revenue_zone: int, green_amount: double, green_number_records: bigint, yellow_amount: double, yellow_number_records: bigint, Borough: string, Zone: string, service_zone: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = spark.read.parquet(\"../data/tmp/revenue-zones\")\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025a720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
